{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stage2T4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6Uvmew_ps1y",
        "colab_type": "code",
        "outputId": "194a7a85-e77c-4d9f-b925-e423b99630a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon May  4 20:40:49 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P8    12W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzy30xHEp6qF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1bc2ab81-f268-47e2-a84f-d6718da8c88b"
      },
      "source": [
        "import os\n",
        "#!rm -r sample_data\n",
        "\n",
        "#clone repo multiple-objects-gan\n",
        "!git clone https://github.com/tohinz/multiple-objects-gan.git\n",
        "\n",
        "#Clone repo COCO-Stack2-GAN\n",
        "!git clone https://github.com/ammarnasr/COCO-Stack2-GAN.git\n",
        "\n",
        "#Move code files coco_s2_train.yml, config.py, utils.py, datasets.py, trainer.py  to their Locations\n",
        "!mv /content/COCO-Stack2-GAN/theCode/coco_s2_train.yml /content/multiple-objects-gan/code/coco/stackgan/cfg/\n",
        "!mv /content/COCO-Stack2-GAN/theCode/config.py        /content/multiple-objects-gan/code/coco/stackgan/miscc/\n",
        "!mv /content/COCO-Stack2-GAN/theCode/utils.py        /content/multiple-objects-gan/code/coco/stackgan/miscc/\n",
        "!mv /content/COCO-Stack2-GAN/theCode/datasets.py    /content/multiple-objects-gan/code/coco/stackgan/miscc/\n",
        "!mv /content/COCO-Stack2-GAN/theCode/trainer.py    /content/multiple-objects-gan/code/coco/stackgan/\n",
        "\n",
        "#Remove the Repo\n",
        "!rm -r /content/COCO-Stack2-GAN/\n",
        "\n",
        "#Changing Working dirctory to data\n",
        "os.chdir('/content/multiple-objects-gan/data/')\n",
        "print(os.getcwd())\n",
        "print(\"Check Marker in first Comment of every file for Sucess!\")\n",
        "print(\"---------------------------------------------------------------------\")\n",
        "print(\"---------------------------------------------------------------------\")\n",
        "\n",
        "#Downloads data-ms-coco.zip (4.11M) , Extract it , and remove unnesscery files\n",
        "!wget https://www2.informatik.uni-hamburg.de/wtm/software/multiple-objects-gan/data-ms-coco.zip\n",
        "!unzip -q data-ms-coco.zip\n",
        "!rm data-ms-coco.zip\n",
        "\n",
        "#Check Working Directory And verify complete download\n",
        "print(os.getcwd())\n",
        "print(\"Check data-ms-coco.zip (4.11M) for Sucess!\")\n",
        "print(\"---------------------------------------------------------------------\")\n",
        "print(\"---------------------------------------------------------------------\")\n",
        "\n",
        "#Downloads coco.zip (1.48G) , Extract it , remove unnesscery files and reorder data\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=0B3y_msrWZaXLQXVzOENCY2E3TlU' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=0B3y_msrWZaXLQXVzOENCY2E3TlU\" -O coco.zip && rm -rf /tmp/cookies.txt\n",
        "!unzip -q coco.zip\n",
        "!rm -r __MACOSX/\n",
        "!rm README.md\n",
        "!rm coco.zip\n",
        "!mv coco/test/filename.txt MS-COCO/test/\n",
        "!mv coco/test/filenames.pickle MS-COCO/test/\n",
        "!mv coco/train/char-CNN-RNN-embeddings.pickle MS-COCO/train/\n",
        "!mv coco/train/filenames.pickle MS-COCO/train/\n",
        "!rm -r coco/\n",
        "\n",
        "#Change Working Directory And verify complete download\n",
        "os.chdir('/content/multiple-objects-gan/data/MS-COCO/train/')\n",
        "print(os.getcwd())\n",
        "print(\"Check coco.zip (1.48G) for Sucess!\")\n",
        "print(\"---------------------------------------------------------------------\")\n",
        "print(\"---------------------------------------------------------------------\")\n",
        "\n",
        "#Downloads train2014.zip (12.58G) , Extract it , and remove unnesscery files\n",
        "!wget http://images.cocodataset.org/zips/train2014.zip\n",
        "!unzip -q train2014.zip\n",
        "!rm train2014.zip\n",
        "\n",
        "#Create & Change Working Directory And verify complete download\n",
        "os.chdir('/content/multiple-objects-gan/data/')\n",
        "print(os.getcwd())\n",
        "os.mkdir('models')\n",
        "os.chdir('/content/multiple-objects-gan/data/models/')\n",
        "print(os.getcwd())\n",
        "print(\"Check train2014.zip (12.58G) for Sucess!\")\n",
        "print(\"---------------------------------------------------------------------\")\n",
        "print(\"---------------------------------------------------------------------\")\n",
        "\n",
        "#Move pretrained_model.pth (455.37M) to created directory\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1XlBL5ZvK-SosZsx8WWcHddmBnHm8TpAU' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1XlBL5ZvK-SosZsx8WWcHddmBnHm8TpAU\" -O pretrained_model.pth && rm -rf /tmp/cookies.txt\n",
        "\n",
        "#Change Working Directory And verify complete download\n",
        "os.chdir('/content/multiple-objects-gan/')\n",
        "print(os.getcwd())\n",
        "print(\"Check pretrained_model.pth (455.37M) for Sucess!\")\n",
        "print(\"---------------------------------------------------------------------\")\n",
        "print(\"---------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "#The Command !sh train.sh coco-stackgan-2 '0' #12:30 am , 2/1/2020 epoch 14 at 3:20 am"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'multiple-objects-gan'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects:   5% (1/17)\u001b[K\rremote: Counting objects:  11% (2/17)\u001b[K\rremote: Counting objects:  17% (3/17)\u001b[K\rremote: Counting objects:  23% (4/17)\u001b[K\rremote: Counting objects:  29% (5/17)\u001b[K\rremote: Counting objects:  35% (6/17)\u001b[K\rremote: Counting objects:  41% (7/17)\u001b[K\rremote: Counting objects:  47% (8/17)\u001b[K\rremote: Counting objects:  52% (9/17)\u001b[K\rremote: Counting objects:  58% (10/17)\u001b[K\rremote: Counting objects:  64% (11/17)\u001b[K\rremote: Counting objects:  70% (12/17)\u001b[K\rremote: Counting objects:  76% (13/17)\u001b[K\rremote: Counting objects:  82% (14/17)\u001b[K\rremote: Counting objects:  88% (15/17)\u001b[K\rremote: Counting objects:  94% (16/17)\u001b[K\rremote: Counting objects: 100% (17/17)\u001b[K\rremote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects:   6% (1/15)\u001b[K\rremote: Compressing objects:  13% (2/15)\u001b[K\rremote: Compressing objects:  20% (3/15)\u001b[K\rremote: Compressing objects:  26% (4/15)\u001b[K\rremote: Compressing objects:  33% (5/15)\u001b[K\rremote: Compressing objects:  40% (6/15)\u001b[K\rremote: Compressing objects:  46% (7/15)\u001b[K\rremote: Compressing objects:  53% (8/15)\u001b[K\rremote: Compressing objects:  60% (9/15)\u001b[K\rremote: Compressing objects:  66% (10/15)\u001b[K\rremote: Compressing objects:  73% (11/15)\u001b[K\rremote: Compressing objects:  80% (12/15)\u001b[K\rremote: Compressing objects:  86% (13/15)\u001b[K\rremote: Compressing objects:  93% (14/15)\u001b[K\rremote: Compressing objects: 100% (15/15)\u001b[K\rremote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "Receiving objects:   0% (1/415)   \rReceiving objects:   1% (5/415)   \rReceiving objects:   2% (9/415)   \rReceiving objects:   3% (13/415)   \rReceiving objects:   4% (17/415)   \rReceiving objects:   5% (21/415)   \rReceiving objects:   6% (25/415)   \rReceiving objects:   7% (30/415)   \rReceiving objects:   8% (34/415)   \rReceiving objects:   9% (38/415)   \rReceiving objects:  10% (42/415)   \rReceiving objects:  11% (46/415)   \rReceiving objects:  12% (50/415)   \rReceiving objects:  13% (54/415)   \rReceiving objects:  14% (59/415)   \rReceiving objects:  15% (63/415)   \rReceiving objects:  16% (67/415)   \rReceiving objects:  17% (71/415)   \rReceiving objects:  18% (75/415)   \rReceiving objects:  19% (79/415)   \rReceiving objects:  20% (83/415)   \rReceiving objects:  21% (88/415)   \rReceiving objects:  22% (92/415)   \rReceiving objects:  23% (96/415)   \rReceiving objects:  24% (100/415)   \rReceiving objects:  25% (104/415)   \rReceiving objects:  26% (108/415)   \rReceiving objects:  27% (113/415)   \rReceiving objects:  28% (117/415)   \rReceiving objects:  29% (121/415)   \rReceiving objects:  30% (125/415)   \rReceiving objects:  31% (129/415)   \rReceiving objects:  32% (133/415)   \rReceiving objects:  33% (137/415)   \rReceiving objects:  34% (142/415)   \rReceiving objects:  35% (146/415)   \rReceiving objects:  36% (150/415)   \rReceiving objects:  37% (154/415)   \rReceiving objects:  38% (158/415)   \rReceiving objects:  39% (162/415)   \rReceiving objects:  40% (166/415)   \rReceiving objects:  41% (171/415)   \rReceiving objects:  42% (175/415)   \rReceiving objects:  43% (179/415)   \rReceiving objects:  44% (183/415), 1.98 MiB | 3.86 MiB/s   \rReceiving objects:  45% (187/415), 1.98 MiB | 3.86 MiB/s   \rReceiving objects:  46% (191/415), 1.98 MiB | 3.86 MiB/s   \rReceiving objects:  47% (196/415), 1.98 MiB | 3.86 MiB/s   \rReceiving objects:  48% (200/415), 1.98 MiB | 3.86 MiB/s   \rReceiving objects:  49% (204/415), 1.98 MiB | 3.86 MiB/s   \rReceiving objects:  50% (208/415), 1.98 MiB | 3.86 MiB/s   \rReceiving objects:  50% (210/415), 19.87 MiB | 19.64 MiB/s   \rremote: Total 415 (delta 4), reused 0 (delta 0), pack-reused 398\u001b[K\n",
            "Receiving objects:  51% (212/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  52% (216/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  53% (220/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  54% (225/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  55% (229/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  56% (233/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  57% (237/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  58% (241/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  59% (245/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  60% (249/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  61% (254/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  62% (258/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  63% (262/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  64% (266/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  65% (270/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  66% (274/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  67% (279/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  68% (283/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  69% (287/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  70% (291/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  71% (295/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  72% (299/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  73% (303/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  74% (308/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  75% (312/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  76% (316/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  77% (320/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  78% (324/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  79% (328/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  80% (332/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  81% (337/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  82% (341/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  83% (345/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  84% (349/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  85% (353/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  86% (357/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  87% (362/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  88% (366/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  89% (370/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  90% (374/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  91% (378/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  92% (382/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  93% (386/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  94% (391/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  95% (395/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  96% (399/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  97% (403/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  98% (407/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects:  99% (411/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects: 100% (415/415), 19.87 MiB | 19.64 MiB/s   \rReceiving objects: 100% (415/415), 23.04 MiB | 21.18 MiB/s, done.\n",
            "Resolving deltas: 100% (189/189), done.\n",
            "Cloning into 'COCO-Stack2-GAN'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 36 (delta 8), reused 29 (delta 7), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (36/36), done.\n",
            "rm: cannot remove '/content/multip-gan/': No such file or directory\n",
            "/content/multiple-objects-gan/data\n",
            "Check Marker in first Comment of every file for Sucess!\n",
            "---------------------------------------------------------------------\n",
            "---------------------------------------------------------------------\n",
            "--2020-05-04 20:59:45--  https://www2.informatik.uni-hamburg.de/wtm/software/multiple-objects-gan/data-ms-coco.zip\n",
            "Resolving www2.informatik.uni-hamburg.de (www2.informatik.uni-hamburg.de)... 134.100.9.79\n",
            "Connecting to www2.informatik.uni-hamburg.de (www2.informatik.uni-hamburg.de)|134.100.9.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4312414 (4.1M) [application/zip]\n",
            "Saving to: ‘data-ms-coco.zip’\n",
            "\n",
            "data-ms-coco.zip    100%[===================>]   4.11M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2020-05-04 20:59:45 (65.2 MB/s) - ‘data-ms-coco.zip’ saved [4312414/4312414]\n",
            "\n",
            "/content/multiple-objects-gan/data\n",
            "Check data-ms-coco.zip (4.11M) for Sucess!\n",
            "---------------------------------------------------------------------\n",
            "---------------------------------------------------------------------\n",
            "--2020-05-04 20:59:52--  https://docs.google.com/uc?export=download&confirm=Yk5v&id=0B3y_msrWZaXLQXVzOENCY2E3TlU\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.126.100, 108.177.126.139, 108.177.126.113, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.126.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-a4-docs.googleusercontent.com/docs/securesc/evjs20g81v2fvev8mtcpnca5amcrcdqq/i12li3nuomjolk34vh23imftlqtuvdf5/1588625925000/16427414401649018968/06065895347757081052Z/0B3y_msrWZaXLQXVzOENCY2E3TlU?e=download [following]\n",
            "--2020-05-04 20:59:52--  https://doc-04-a4-docs.googleusercontent.com/docs/securesc/evjs20g81v2fvev8mtcpnca5amcrcdqq/i12li3nuomjolk34vh23imftlqtuvdf5/1588625925000/16427414401649018968/06065895347757081052Z/0B3y_msrWZaXLQXVzOENCY2E3TlU?e=download\n",
            "Resolving doc-04-a4-docs.googleusercontent.com (doc-04-a4-docs.googleusercontent.com)... 172.217.218.132, 2a00:1450:4013:c08::84\n",
            "Connecting to doc-04-a4-docs.googleusercontent.com (doc-04-a4-docs.googleusercontent.com)|172.217.218.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=vfa8ujkvh8stc&continue=https://doc-04-a4-docs.googleusercontent.com/docs/securesc/evjs20g81v2fvev8mtcpnca5amcrcdqq/i12li3nuomjolk34vh23imftlqtuvdf5/1588625925000/16427414401649018968/06065895347757081052Z/0B3y_msrWZaXLQXVzOENCY2E3TlU?e%3Ddownload&hash=faapb81dm2h6b0jbo19kd72e8h1khikt [following]\n",
            "--2020-05-04 20:59:53--  https://docs.google.com/nonceSigner?nonce=vfa8ujkvh8stc&continue=https://doc-04-a4-docs.googleusercontent.com/docs/securesc/evjs20g81v2fvev8mtcpnca5amcrcdqq/i12li3nuomjolk34vh23imftlqtuvdf5/1588625925000/16427414401649018968/06065895347757081052Z/0B3y_msrWZaXLQXVzOENCY2E3TlU?e%3Ddownload&hash=faapb81dm2h6b0jbo19kd72e8h1khikt\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.126.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-04-a4-docs.googleusercontent.com/docs/securesc/evjs20g81v2fvev8mtcpnca5amcrcdqq/i12li3nuomjolk34vh23imftlqtuvdf5/1588625925000/16427414401649018968/06065895347757081052Z/0B3y_msrWZaXLQXVzOENCY2E3TlU?e=download&nonce=vfa8ujkvh8stc&user=06065895347757081052Z&hash=1jbm520hi4i1oiks8ipnv46r3lfl7q4n [following]\n",
            "--2020-05-04 20:59:53--  https://doc-04-a4-docs.googleusercontent.com/docs/securesc/evjs20g81v2fvev8mtcpnca5amcrcdqq/i12li3nuomjolk34vh23imftlqtuvdf5/1588625925000/16427414401649018968/06065895347757081052Z/0B3y_msrWZaXLQXVzOENCY2E3TlU?e=download&nonce=vfa8ujkvh8stc&user=06065895347757081052Z&hash=1jbm520hi4i1oiks8ipnv46r3lfl7q4n\n",
            "Connecting to doc-04-a4-docs.googleusercontent.com (doc-04-a4-docs.googleusercontent.com)|172.217.218.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘coco.zip’\n",
            "\n",
            "coco.zip                [                 <=>]   1.48G  97.2MB/s    in 13s     \n",
            "\n",
            "2020-05-04 21:00:07 (114 MB/s) - ‘coco.zip’ saved [1587844671]\n",
            "\n",
            "/content/multiple-objects-gan/data/MS-COCO/train\n",
            "Check coco.zip (1.48G) for Sucess!\n",
            "---------------------------------------------------------------------\n",
            "---------------------------------------------------------------------\n",
            "--2020-05-04 21:01:11--  http://images.cocodataset.org/zips/train2014.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.176.107\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.176.107|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13510573713 (13G) [application/zip]\n",
            "Saving to: ‘train2014.zip’\n",
            "\n",
            "train2014.zip       100%[===================>]  12.58G  34.9MB/s    in 6m 9s   \n",
            "\n",
            "2020-05-04 21:07:20 (34.9 MB/s) - ‘train2014.zip’ saved [13510573713/13510573713]\n",
            "\n",
            "/content/multiple-objects-gan/data\n",
            "/content/multiple-objects-gan/data/models\n",
            "Check train2014.zip (12.58G) for Sucess!\n",
            "---------------------------------------------------------------------\n",
            "---------------------------------------------------------------------\n",
            "--2020-05-04 21:13:53--  https://docs.google.com/uc?export=download&confirm=&id=1XlBL5ZvK-SosZsx8WWcHddmBnHm8TpAU\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.126.101, 108.177.126.113, 108.177.126.138, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.126.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘pretrained_model.pth’\n",
            "\n",
            "pretrained_model.pt     [ <=>                ]   3.20K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-05-04 21:13:53 (46.4 MB/s) - ‘pretrained_model.pth’ saved [3273]\n",
            "\n",
            "/content/multiple-objects-gan\n",
            "Check pretrained_model.pth (455.37M) for Sucess!\n",
            "---------------------------------------------------------------------\n",
            "---------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzdu9QDEYoBG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3001ab1d-d39d-4475-8d8a-8ee57d82ab1b"
      },
      "source": [
        "!sh train.sh coco-stackgan-2 '0' #12:30 am , 2/1/2020 epoch 14 at 3:20 am"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training on the MS-COCO data set.\n",
            "Using config:\n",
            "{'CONFIG_NAME': 'stageII',\n",
            " 'CUDA': True,\n",
            " 'DATASET_NAME': 'coco',\n",
            " 'DATA_DIR': '../../../data/MS-COCO',\n",
            " 'EMBEDDING_TYPE': 'cnn-rnn',\n",
            " 'GAN': {'CONDITION_DIM': 128, 'DF_DIM': 96, 'GF_DIM': 192, 'R_NUM': 2},\n",
            " 'GPU_ID': '0',\n",
            " 'IMG_DIR': '../../../data/MS-COCO/train/train2014',\n",
            " 'IMSIZE': 256,\n",
            " 'NET_D': '',\n",
            " 'NET_G': '',\n",
            " 'STAGE': 2,\n",
            " 'STAGE1_G': '../../../data/models/pretrained_model.pth',\n",
            " 'TEXT': {'DIMENSION': 1024},\n",
            " 'TRAIN': {'BATCH_SIZE': 24,\n",
            "           'COEFF': {'KL': 2.0},\n",
            "           'DISCRIMINATOR_LR': 0.0002,\n",
            "           'FLAG': True,\n",
            "           'GENERATOR_LR': 0.0002,\n",
            "           'LR_DECAY_EPOCH': 20,\n",
            "           'MAX_EPOCH': 120,\n",
            "           'PRETRAINED_EPOCH': 600,\n",
            "           'PRETRAINED_MODEL': '',\n",
            "           'SNAPSHOT_INTERVAL': 2},\n",
            " 'USE_BBOX_LAYOUT': True,\n",
            " 'USE_LOCAL_PATHWAY': True,\n",
            " 'VIS_COUNT': 64,\n",
            " 'WORKERS': 16,\n",
            " 'Z_DIM': 100}\n",
            "Load filenames from: ../../../data/MS-COCO/train/filenames.pickle (82783)\n",
            "tcmalloc: large alloc 1695399936 bytes == 0xf7dba000 @  0x7f9de34661e7 0x7f9d97c715e1 0x7f9d97cd4138 0x7f9d97cd7278 0x7f9d97cd7855 0x7f9d97d6eb1d 0x50ac25 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x509642 0x595311 0x54a6ff 0x551b81 0x5aa6ec 0x50abb3 0x50d390 0x508245 0x50b403 0x635222 0x6352d7 0x638a8f 0x639631 0x4b0f40 0x7f9de3063b97 0x5b2fda\n",
            "2020-05-04 21:18:50.488419: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "STAGE2_G(\n",
            "  (STAGE1_G): STAGE1_G(\n",
            "    (ca_net): CA_NET(\n",
            "      (fc): Linear(in_features=1024, out_features=256, bias=True)\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (bbox_net): BBOX_NET(\n",
            "      (encode): Sequential(\n",
            "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "        (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "        (5): Conv2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=292, out_features=24576, bias=False)\n",
            "      (1): BatchNorm1d(24576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (label): Sequential(\n",
            "      (0): Linear(in_features=209, out_features=128, bias=False)\n",
            "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (local1): Sequential(\n",
            "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (1): Conv2d(128, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "    )\n",
            "    (local2): Sequential(\n",
            "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (1): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "    )\n",
            "    (upsample1): Sequential(\n",
            "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (1): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "    )\n",
            "    (upsample2): Sequential(\n",
            "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (1): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "    )\n",
            "    (upsample3): Sequential(\n",
            "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (1): Conv2d(768, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "    )\n",
            "    (upsample4): Sequential(\n",
            "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (1): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "    )\n",
            "    (img): Sequential(\n",
            "      (0): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (ca_net): CA_NET(\n",
            "    (fc): Linear(in_features=1024, out_features=256, bias=True)\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (label): Sequential(\n",
            "    (0): Linear(in_features=209, out_features=128, bias=False)\n",
            "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (local1): Sequential(\n",
            "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (1): Conv2d(896, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "  )\n",
            "  (local2): Sequential(\n",
            "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (1): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "  )\n",
            "  (encoder): Sequential(\n",
            "    (0): Conv2d(3, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(192, 384, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Conv2d(384, 768, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): ReLU(inplace=True)\n",
            "  )\n",
            "  (hr_joint): Sequential(\n",
            "    (0): Conv2d(1024, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (residual): Sequential(\n",
            "    (0): ResBlock(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): ResBlock(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (upsample1): Sequential(\n",
            "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (1): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "  )\n",
            "  (upsample2): Sequential(\n",
            "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (1): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "  )\n",
            "  (upsample3): Sequential(\n",
            "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (1): Conv2d(384, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "  )\n",
            "  (upsample4): Sequential(\n",
            "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (1): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "  )\n",
            "  (img): Sequential(\n",
            "    (0): Conv2d(48, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): Tanh()\n",
            "  )\n",
            ")\n",
            "Load from:  ../../../data/models/pretrained_model.pth\n",
            "STAGE2_D(\n",
            "  (local): Sequential(\n",
            "    (0): Conv2d(84, 192, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (3): Conv2d(192, 192, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  (conv1): Conv2d(3, 96, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (conv2): Conv2d(96, 192, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(192, 384, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4): Conv2d(576, 768, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv5): Conv2d(768, 1536, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn5): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv6): Conv2d(1536, 3072, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn6): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv7): Conv2d(3072, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn7): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv8): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn8): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (get_cond_logits): D_GET_LOGITS(\n",
            "    (outlogits): Sequential(\n",
            "      (0): Conv2d(896, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (3): Conv2d(768, 1, kernel_size=(4, 4), stride=(4, 4))\n",
            "    )\n",
            "  )\n",
            "  (get_uncond_logits): D_GET_LOGITS(\n",
            "    (outlogits): Sequential(\n",
            "      (0): Conv2d(768, 1, kernel_size=(4, 4), stride=(4, 4))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "epoch :  0  drive_count :  0\n",
            "0\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3226: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
            "epoch     :   0\n",
            "count     :   1\n",
            "  i       :   0\n",
            "Time to i :  19.326300144195557\n",
            "D_loss :  1.7996065616607666\n",
            "D_loss_real :  1.0525763034820557\n",
            "D_loss_wrong :  0.24092911183834076\n",
            "D_loss_fake :  1.0000808238983154\n",
            "G_loss :  32.25298309326172\n",
            "KL_loss :  0.0031118709594011307\n",
            "generator_lr :  0.0002\n",
            "discriminator_lr :  0.0002\n",
            "lr_decay_step :  20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n3-r9VijHuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}